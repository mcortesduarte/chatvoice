{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Función_recolección.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoNcKjsdi23WmK/TX0fvQu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcortesduarte/chatvoice/blob/master/Funci%C3%B3n_busqueda_Palabras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vq4GF_mNRS1e"
      },
      "source": [
        "!pip install --user -U nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu5l6SAeRb35"
      },
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgxy1fcUHXhD",
        "outputId": "cf22f5bd-5f85-41e4-ce74-5594d2324b69"
      },
      "source": [
        "!python -m spacy download es_core_news_md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-28 17:18:03.690529: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\u001b[0m\n",
            "\u001b[33mWARNING: Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\u001b[0m\n",
            "Collecting es-core-news-md==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.1.0/es_core_news_md-3.1.0-py3-none-any.whl (42.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.7 MB 44 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-md==3.1.0) (3.1.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (8.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (0.3.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.0.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (4.41.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (21.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (5.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->es-core-news-md==3.1.0) (2.0.1)\n",
            "Installing collected packages: es-core-news-md\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/10151>\n",
            "  distutils: /usr/local/include/python3.7/es-core-news-md\n",
            "  sysconfig: /usr/include/python3.7m/es-core-news-md\u001b[0m\n",
            "Successfully installed es-core-news-md-3.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFdycvNERihu",
        "outputId": "de5baead-8f60-428d-d416-f31b3fc7db7e"
      },
      "source": [
        "import json\n",
        "import nltk \n",
        "from nltk.corpus import cess_esp\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag.stanford import POSTagger\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('cess_esp')\n",
        "nltk.download('stopwords')\n",
        "KeyWords = json.loads(open('TiposE-Sebas.json').read())\n",
        "existe = []\n",
        "saluda = []\n",
        "encontrar = []#ubicacion \n",
        "costos = []\n",
        "for categoria in KeyWords['Categorias']:\n",
        "    for patron in categoria['patron']:\n",
        "        if (categoria['clasificacion']=='Saludos'):\n",
        "            saluda.append(patron)\n",
        "        if (categoria['clasificacion']=='Existencia'):\n",
        "            existe.append(patron)\n",
        "        if (categoria['clasificacion']=='Ubicación'):\n",
        "            encontrar.append(patron)\n",
        "        if (categoria['clasificacion']=='Costos'):\n",
        "            costos.append(patron)\n",
        "print(existe)\n",
        "print(encontrar)\n",
        "print(costos)\n",
        "omitir = ['?','¿',',','.','!','¡']\n",
        "basura = stopwords.words('spanish')\n",
        "def Obtener_Orden(mensaje):\n",
        "    TextoLista = word_tokenize(mensaje.lower(),language=\"spanish\")\n",
        "    ListaPalabrasClave = []\n",
        "    for i in range(len(TextoLista)):\n",
        "        if (TextoLista[i] not in omitir):\n",
        "            if (TextoLista[i] in existe):\n",
        "                print(TextoLista[i])\n",
        "                ListaPalabrasClave.append({'Existe':(TextoLista[i],i)})\n",
        "            if (TextoLista[i] in encontrar):\n",
        "                print(TextoLista[i])\n",
        "                ListaPalabrasClave.append({'Encontrar':(TextoLista[i],i)})\n",
        "            if (TextoLista[i] in costos):\n",
        "                print(TextoLista[i])\n",
        "                ListaPalabrasClave.append({'Costos':(TextoLista[i],i)})\n",
        "    print (ListaPalabrasClave)     \n",
        "    return (ListaPalabrasClave)\n",
        "a=str(input(\"prueba: \"))\n",
        "Obtener_Orden(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['encontrar', 'encuentro', 'buscando', 'busco', 'quedan', 'tiene']\n",
            "['donde', 'pasillo', 'que pasillo', 'encuentran', 'encontrar', 'ubica']\n",
            "['cuesta', 'precio', 'costo', 'vale', 'valor']\n",
            "prueba: donde estan los marruchan\n",
            "donde\n",
            "[{'Encontrar': ('donde', 0)}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Encontrar': ('donde', 0)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJbuLuLdemSe"
      },
      "source": [
        "Aquí se guardarán las palabras escritas en el json. Al igual que las palabras basura tales como artículos, conectores,etc. Que no contribuyen mucho a lo que estamos haciendo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEnQ57wbfByL"
      },
      "source": [
        "\"\"\"existe = []\n",
        "saluda = []\n",
        "encontrar = []#ubicacion \n",
        "costos = []\n",
        "for categoria in KeyWords['Categorias']:\n",
        "    for patron in categoria['patron']:\n",
        "        if (categoria['clasificacion']=='Saludos'):\n",
        "            saluda.append(patron)\n",
        "        if (categoria['clasificacion']=='Existencia'):\n",
        "            existe.append(patron)\n",
        "        if (categoria['clasificacion']=='Ubicación'):\n",
        "            encontrar.append(patron)\n",
        "        if (categoria['clasificacion']=='Costos'):\n",
        "            costos.append(patron)\n",
        "print(existe)\n",
        "print(encontrar)\n",
        "print(costos)\n",
        "omitir = ['?','¿',',','.','!','¡']\n",
        "basura = stopwords.words('spanish')\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpSLGL4rfGrO"
      },
      "source": [
        "Esta será la función a la que llamaremos en el otro programa. Recibe la palabra y reconoce cuales son las que indican una orden, al igual que arroja la posición para saber hacia cual producto esta aplicada esta orden. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUELAmVmfXJC"
      },
      "source": [
        "\n",
        "\"\"\"def Obtener_Orden(mensaje):\n",
        "    TextoLista = Word_tokenize(mensaje.lower(),language=\"spanish\")\n",
        "    ListaPalabrasClave = []\n",
        "    for i in range(len(TextoLista)):\n",
        "        if (TextoLista[i] not in omitir):\n",
        "            if (TextoLista[i] in existe):\n",
        "                print(TextoLista[i])\n",
        "                ListaPalabrasClave.append({'Existe':(TextoLista[i],i)})\n",
        "            if (TextoLista[i] in encontrar):\n",
        "                print(TextoLista[i])\n",
        "                ListaPalabrasClave.append({'Encontrar':(TextoLista[i],i)})\n",
        "            if (TextoLista[i] in costos):\n",
        "                print(TextoLista[i])\n",
        "                ListaPalabrasClave.append({'Costos':(TextoLista[i],i)})\n",
        "    print (ListaPalabrasClave)     \n",
        "    return (ListaPalabrasClave)\n",
        "a=str(input(\"prueba: \"))\n",
        "Obtener_Orden(a)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqPWvbXPfbY-"
      },
      "source": [
        "El siguiente será una función que identifica cual es la posición en la que esta el producto, para relacionarlo con la orden. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoF1JTTCVHVD",
        "outputId": "bd155e58-5fa9-4245-e1d2-03fc331ce28c"
      },
      "source": [
        "import spacy\n",
        "\n",
        "def obtener_producto(mensaje):\n",
        "  productos = []\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  doc = nlp(mensaje)\n",
        "  i=0\n",
        "  for prod in doc:\n",
        "    i=i+1\n",
        "    productos.append(prod)\n",
        "    print(prod)\n",
        "  return productos\n",
        "z= str(input(\"hablalo pri:\"))\n",
        "obtener_producto(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hablalo pri:quiero guayabas  con sabor a maruchan de res\n",
            "a maruchan de res\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}